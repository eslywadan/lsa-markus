# 共現統計
 **「共現統計的數學模型」**

用數學與機率統計的方法，去描述與量化「多個事件／特徵在同一情境中一起出現」的規律與結構。

它不是單一一個公式，而是一類建模思想與工具集合，廣泛用在 NLP、資訊檢索、資料探勘、機器學習、網路分析、推薦系統等領域。

## 直觀 → 數學形式 → 常見模型 


一、什麼是「共現」？（直觀）

共現（co-occurrence） 的意思是：

兩個（或多個）元素在同一個「上下文」中同時出現。

例子：
	•	語言中：「人工」和「智慧」常在同一句或同一文件出現
	•	文件中：關鍵詞 A 和 B 同時出現在同一篇論文
	•	社交網路：兩個人同時出現在同一群組
	•	商品：商品 A 和 B 被同一個使用者購買
	•	生物資訊：基因 A 與基因 B 在同一條路徑中被表達


二、最基本的數學表示：共現矩陣

1️⃣ 共現矩陣（Co-occurrence Matrix）

設有一組元素 $x_1, x_2, \dots, x_n$，
定義矩陣：

$C_{ij} = \text{「}x_i\text{ 與 }x_j\text{ 同時出現的次數」}$

這就是最原始的 共現統計模型。

例如詞彙共現矩陣：

```yaml
	    AI	 data  model
AI	    –	  25	  18
data	25	   –	  40
model	18	  40	  –
```


 

三、從「次數」到「機率」的數學模型

2️⃣ 聯合機率模型

把次數正規化後：

$P(x_i, x_j) = \frac{C_{ij}}{\sum_{i,j} C_{ij}}$

並可得到邊際機率：

$P(x_i) = \sum_j P(x_i, x_j)$

這時就進入機率論的共現模型。

四、關聯強度的數學量化（非常重要）

光看次數是不夠的，必須排除「常出現但不特別相關」。

3️⃣ PMI（Pointwise Mutual Information）

$\text{PMI}(x_i, x_j)
= \log \frac{P(x_i, x_j)}{P(x_i)P(x_j)}$

意義：
```
	•	PMI > 0：比隨機更常一起出現
	•	PMI = 0：獨立
	•	PMI < 0：互斥
```

這是共現統計最經典的數學模型之一。

NLP 中的 PPMI + SVD 幾乎奠定了現代詞向量方法（如 word2vec 的數學背景）。


五、圖模型觀點（結構化共現）

4️⃣ 共現圖（Graph Model）
```
	•	節點：元素（詞、商品、人）
	•	邊權重：共現強度（次數、PMI、機率）
```

用圖論工具：
```
	•	拉普拉斯矩陣
	•	譜分解（eigen / SVD）
	•	社群偵測
```

 


六、潛在變量模型（高階共現模型）

5️⃣ 潛在語意分析（LSA）

假設：

表面共現是由隱含語意空間產生

數學形式：
$C \approx U \Sigma V^T$

也就是 SVD。

這說明：
	•	共現矩陣是高維、稀疏、雜訊多
	•	真正結構存在低維潛在子空間中

 

6️⃣ 主題模型（LDA）

將共現視為：
$P(w, d) = \sum_k P(w|z_k)P(z_k|d)$

其中：
- 	$z_k$ 是潛在主題 
- 	本質上仍是共現的機率生成模型

⸻

七、與你之前問題的關係（非常關鍵）

你之前問過：
	•	✅ 行列式
	•	✅ SVD
	•	✅ 特徵值
	•	✅ Boone’s lemma
	•	✅ undecidability

這裡的關聯是：

共現統計 → 矩陣 → 特徵分解 / SVD → 潛在結構發現

層次	數學工具
次數	計數論
機率	機率論、資訊論
結構	線性代數
降維	SVD / eigen
推理	潛在變量模型

這是現代 AI / NLP / 資料分析的數學主線之一。

⸻

八、簡明定義（可直接引用）

共現統計的數學模型是指：
利用矩陣、機率分佈、資訊量與線性代數方法，
來描述多個離散元素在同一上下文中共同出現的統計結構，
並藉此推斷潛在關係與隱含語意的數學框架。

⸻

九、一句話版本

共現統計不是在數「一起出現幾次」，而是在用數學找出「為什麼會一起出現」。

如果你願意，我可以下一步直接：
	•	從 共現矩陣 → SVD → 詞向量 做一個完整數學推導
	•	或把它連結到 知識圖譜 / 本體 / agentic reasoning（你之前提過）
